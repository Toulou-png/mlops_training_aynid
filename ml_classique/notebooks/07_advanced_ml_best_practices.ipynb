{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "a1674b7d",
   "metadata": {},
   "source": [
    "# Module 7: Aspects Avancés et Bonnes Pratiques"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "890b7fd8",
   "metadata": {},
   "source": [
    "## 7.1 Sélection et Validation de Modèles\n",
    "\n",
    "### Méthodes de rééchantillonnage\n",
    "\n",
    "Les méthodes de rééchantillonnage sont des techniques utilisées pour estimer la performance d'un modèle de Machine Learning en créant plusieurs échantillons à partir des données d'entraînement. Ces méthodes permettent d'obtenir une estimation plus robuste de la performance du modèle et de réduire le risque de surapprentissage."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4ce2fa70",
   "metadata": {},
   "source": [
    "### Bootstrap\n",
    "\n",
    "Le bootstrap est une méthode de rééchantillonnage qui consiste à créer plusieurs échantillons en tirant aléatoirement avec remplacement à partir des données d'entraînement. Chaque échantillon bootstrap a la même taille que les données d'entraînement, mais certaines observations peuvent être répétées et d'autres peuvent être absentes.\n",
    "\n",
    "Le bootstrap est utilisé pour estimer la variance et les intervalles de confiance des estimateurs statistiques, et pour évaluer la performance des modèles de Machine Learning.\n",
    "\n",
    "Voici un exemple en Python utilisant `scikit-learn` :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "36917625",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bootstrap Sample 1: [3 1 8 5 8 3 1 9 6 6]\n",
      "Bootstrap Sample 2: [10  1  5  4  7  2  8  2  1 10]\n",
      "Bootstrap Sample 3: [ 4  4 10 10  7  2  2  9  9  1]\n",
      "Bootstrap Sample 4: [ 9 10  7  5  9  7  6  7  7  3]\n",
      "Bootstrap Sample 5: [ 9 10  7  2  6  5  3  6  9  5]\n",
      "Bootstrap Sample 6: [5 2 7 6 5 1 8 7 4 4]\n",
      "Bootstrap Sample 7: [ 7  5  8 10  3  6  6  7  1  6]\n",
      "Bootstrap Sample 8: [4 8 9 9 2 8 2 5 5 3]\n",
      "Bootstrap Sample 9: [ 5 10  8  4 10  8  2  9  1  2]\n",
      "Bootstrap Sample 10: [ 4  2  1  5  2  5 10  8  7 10]\n",
      "Mean of Bootstrap Means: 5.659999999999999\n"
     ]
    }
   ],
   "source": [
    "# filepath: c:\\Users\\michel.bertrand.mama\\Documents\\AYNID\\advanced_ml_best_practices.ipynb\n",
    "from sklearn.utils import resample\n",
    "import numpy as np\n",
    "\n",
    "# Générer des données aléatoires pour l'exemple\n",
    "data = np.array([1, 2, 3, 4, 5, 6, 7, 8, 9, 10])\n",
    "\n",
    "# Créer un échantillon bootstrap\n",
    "n_iterations = 10\n",
    "n_size = int(len(data))\n",
    "values = []\n",
    "for i in range(n_iterations):\n",
    "    sample = resample(data, n_samples=n_size)\n",
    "    values.append(np.mean(sample))\n",
    "    print(f\"Bootstrap Sample {i+1}: {sample}\")\n",
    "\n",
    "print(f\"Mean of Bootstrap Means: {np.mean(values)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d17f8466",
   "metadata": {},
   "source": [
    "### Validation croisée k-fold\n",
    "\n",
    "La validation croisée k-fold est une méthode de rééchantillonnage qui consiste à diviser les données d'entraînement en k sous-ensembles (folds) de taille égale. Le modèle est entraîné sur k-1 folds et évalué sur le fold restant. Ce processus est répété k fois, chaque fois avec un fold différent pour l'évaluation. Les résultats sont ensuite moyennés pour obtenir une estimation de la performance du modèle.\n",
    "\n",
    "La validation croisée k-fold est utilisée pour évaluer la performance des modèles de Machine Learning et pour comparer différents modèles.\n",
    "\n",
    "Voici un exemple en Python utilisant `scikit-learn` :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "272379d1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TRAIN: [4 5 6 7] TEST: [0 1 2 3]\n",
      "MSE: 5.000000000000002\n",
      "TRAIN: [0 1 2 3] TEST: [4 5 6 7]\n",
      "MSE: 5.0000000000000036\n"
     ]
    }
   ],
   "source": [
    "# filepath: c:\\Users\\michel.bertrand.mama\\Documents\\AYNID\\advanced_ml_best_practices.ipynb\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.metrics import mean_squared_error\n",
    "import numpy as np\n",
    "\n",
    "# Générer des données aléatoires pour l'exemple\n",
    "X = np.array([[1, 2], [3, 4], [1, 2], [3, 4], [5, 6], [7, 8], [5, 6], [7, 8]])\n",
    "y = np.array([1, 2, 3, 4, 5, 6, 7, 8])\n",
    "\n",
    "# Créer un objet KFold avec k=2\n",
    "kf = KFold(n_splits=2)\n",
    "\n",
    "# Itérer sur les folds\n",
    "for train_index, test_index in kf.split(X):\n",
    "    print(\"TRAIN:\", train_index, \"TEST:\", test_index)\n",
    "    X_train, X_test = X[train_index], X[test_index]\n",
    "    y_train, y_test = y[train_index], y[test_index]\n",
    "\n",
    "    # Entraîner un modèle de régression linéaire\n",
    "    model = LinearRegression()\n",
    "    model.fit(X_train, y_train)\n",
    "\n",
    "    # Faire des prédictions\n",
    "    y_pred = model.predict(X_test)\n",
    "\n",
    "    # Calculer l'erreur quadratique moyenne\n",
    "    mse = mean_squared_error(y_test, y_pred)\n",
    "    print(\"MSE:\", mse)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "256be173",
   "metadata": {},
   "source": [
    "### Critères de sélection\n",
    "\n",
    "Les critères de sélection sont des mesures utilisées pour comparer différents modèles de Machine Learning et choisir le meilleur modèle. Les critères courants comprennent :\n",
    "\n",
    "*   **Précision (Accuracy) :** Le pourcentage de prédictions correctes.\n",
    "*   **Précision (Precision) :** La proportion de prédictions positives correctes parmi toutes les prédictions positives.\n",
    "*   **Rappel (Recall) :** La proportion de vrais positifs correctement identifiés.\n",
    "*   **F1-score :** La moyenne harmonique de la précision et du rappel.\n",
    "*   **Erreur quadratique moyenne (MSE) :** La moyenne des carrés des erreurs entre les valeurs prédites et les valeurs réelles.\n",
    "*   **Erreur absolue moyenne (MAE) :** La moyenne des valeurs absolues des erreurs.\n",
    "*   **Coefficient de détermination (R²) :** La proportion de la variance de la variable cible expliquée par le modèle."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "53aeb4f1",
   "metadata": {},
   "source": [
    "### AIC, BIC\n",
    "\n",
    "AIC (Akaike Information Criterion) et BIC (Bayesian Information Criterion) sont des critères d'information utilisés pour sélectionner des modèles statistiques. Ils mesurent la qualité d'un modèle en tenant compte de sa complexité.\n",
    "\n",
    "*   **AIC :** AIC = 2k - 2ln(L), où k est le nombre de paramètres du modèle et L est la vraisemblance maximale du modèle.\n",
    "*   **BIC :** BIC = kln(n) - 2ln(L), où k est le nombre de paramètres du modèle, n est le nombre d'observations, et L est la vraisemblance maximale du modèle.\n",
    "\n",
    "Les modèles avec des valeurs AIC ou BIC plus faibles sont préférés."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "857dc077",
   "metadata": {},
   "source": [
    "### Validation sur hold-out set\n",
    "\n",
    "La validation sur hold-out set consiste à diviser les données en deux sous-ensembles : un ensemble d'entraînement et un ensemble de test (hold-out set). Le modèle est entraîné sur l'ensemble d'entraînement et évalué sur l'ensemble de test.\n",
    "\n",
    "La validation sur hold-out set est utilisée pour estimer la performance du modèle sur des données non vues et pour détecter le surapprentissage."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "27231404",
   "metadata": {},
   "source": [
    "## 7.2 Ingénierie des Features\n",
    "\n",
    "### Encodage de variables catégorielles\n",
    "\n",
    "L'encodage de variables catégorielles est le processus de transformation des variables catégorielles en variables numériques, car la plupart des modèles de Machine Learning ne peuvent pas traiter directement les variables catégorielles.\n",
    "\n",
    "Les méthodes d'encodage courantes comprennent :\n",
    "\n",
    "*   **One-hot encoding :** Créer une variable binaire pour chaque catégorie.\n",
    "*   **Label encoding :** Attribuer un entier unique à chaque catégorie.\n",
    "*   **Ordinal encoding :** Attribuer un entier à chaque catégorie en fonction de son ordre.\n",
    "\n",
    "Voici un exemple en Python utilisant `pandas` :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3fd436a1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "One-hot encoding:\n",
      "    couleur_bleu  couleur_rouge  couleur_vert\n",
      "0         False           True         False\n",
      "1         False          False          True\n",
      "2          True          False         False\n",
      "3         False           True         False\n",
      "4         False          False          True\n",
      "\n",
      "Label encoding:\n",
      "   couleur  couleur_encoded\n",
      "0   rouge                1\n",
      "1    vert                2\n",
      "2    bleu                0\n",
      "3   rouge                1\n",
      "4    vert                2\n"
     ]
    }
   ],
   "source": [
    "# filepath: c:\\Users\\michel.bertrand.mama\\Documents\\AYNID\\advanced_ml_best_practices.ipynb\n",
    "import pandas as pd\n",
    "\n",
    "# Créer un DataFrame avec une variable catégorielle\n",
    "data = {'couleur': ['rouge', 'vert', 'bleu', 'rouge', 'vert']}\n",
    "df = pd.DataFrame(data)\n",
    "\n",
    "# One-hot encoding\n",
    "df_one_hot = pd.get_dummies(df, columns=['couleur'])\n",
    "print(\"One-hot encoding:\\n\", df_one_hot)\n",
    "\n",
    "# Label encoding\n",
    "df['couleur_encoded'] = df['couleur'].astype('category').cat.codes\n",
    "print(\"\\nLabel encoding:\\n\", df)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "db93511a",
   "metadata": {},
   "source": [
    "### Création de features polynomiales\n",
    "\n",
    "La création de features polynomiales consiste à créer de nouvelles features en combinant les features existantes à l'aide de fonctions polynomiales (par exemple, x², x*y). Cela permet de capturer des relations non linéaires entre les features et la variable cible.\n",
    "\n",
    "Voici un exemple en Python utilisant `scikit-learn` :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "fdb03bea",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Features polynomiales:\n",
      " [[ 1.  1.  2.  1.  2.  4.]\n",
      " [ 1.  3.  4.  9. 12. 16.]\n",
      " [ 1.  5.  6. 25. 30. 36.]]\n"
     ]
    }
   ],
   "source": [
    "# filepath: c:\\Users\\michel.bertrand.mama\\Documents\\AYNID\\advanced_ml_best_practices.ipynb\n",
    "from sklearn.preprocessing import PolynomialFeatures\n",
    "import numpy as np\n",
    "\n",
    "# Générer des données aléatoires pour l'exemple\n",
    "X = np.array([[1, 2], [3, 4], [5, 6]])\n",
    "\n",
    "# Créer un objet PolynomialFeatures avec degré 2\n",
    "poly = PolynomialFeatures(degree=2)\n",
    "\n",
    "# Transformer les données\n",
    "X_poly = poly.fit_transform(X)\n",
    "print(\"Features polynomiales:\\n\", X_poly)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7e00e7d7",
   "metadata": {},
   "source": [
    "### Selection de features\n",
    "\n",
    "La sélection de features est le processus de sélection d'un sous-ensemble de features pertinentes pour un modèle de Machine Learning. Elle peut être utilisée pour simplifier le modèle, réduire le temps de calcul, et améliorer la performance."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0f05e699",
   "metadata": {},
   "source": [
    "### Méthodes filter, wrapper, embedded\n",
    "\n",
    "Il existe trois types de méthodes de sélection de features :\n",
    "\n",
    "*   **Méthodes filter :** Sélectionner les features en fonction de leurs propriétés statistiques (par exemple, la corrélation avec la variable cible).\n",
    "*   **Méthodes wrapper :** Sélectionner les features en évaluant la performance du modèle avec différents sous-ensembles de features.\n",
    "*   **Méthodes embedded :** Sélectionner les features dans le cadre de l'entraînement du modèle (par exemple, en utilisant la régularisation L1).\n",
    "\n",
    "Voici un exemple en Python utilisant `scikit-learn` :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "684dbfe2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Features sélectionnées par filter:\n",
      " [[1.4 0.2]\n",
      " [1.4 0.2]\n",
      " [1.3 0.2]\n",
      " [1.5 0.2]\n",
      " [1.4 0.2]\n",
      " [1.7 0.4]\n",
      " [1.4 0.3]\n",
      " [1.5 0.2]\n",
      " [1.4 0.2]\n",
      " [1.5 0.1]\n",
      " [1.5 0.2]\n",
      " [1.6 0.2]\n",
      " [1.4 0.1]\n",
      " [1.1 0.1]\n",
      " [1.2 0.2]\n",
      " [1.5 0.4]\n",
      " [1.3 0.4]\n",
      " [1.4 0.3]\n",
      " [1.7 0.3]\n",
      " [1.5 0.3]\n",
      " [1.7 0.2]\n",
      " [1.5 0.4]\n",
      " [1.  0.2]\n",
      " [1.7 0.5]\n",
      " [1.9 0.2]\n",
      " [1.6 0.2]\n",
      " [1.6 0.4]\n",
      " [1.5 0.2]\n",
      " [1.4 0.2]\n",
      " [1.6 0.2]\n",
      " [1.6 0.2]\n",
      " [1.5 0.4]\n",
      " [1.5 0.1]\n",
      " [1.4 0.2]\n",
      " [1.5 0.2]\n",
      " [1.2 0.2]\n",
      " [1.3 0.2]\n",
      " [1.4 0.1]\n",
      " [1.3 0.2]\n",
      " [1.5 0.2]\n",
      " [1.3 0.3]\n",
      " [1.3 0.3]\n",
      " [1.3 0.2]\n",
      " [1.6 0.6]\n",
      " [1.9 0.4]\n",
      " [1.4 0.3]\n",
      " [1.6 0.2]\n",
      " [1.4 0.2]\n",
      " [1.5 0.2]\n",
      " [1.4 0.2]\n",
      " [4.7 1.4]\n",
      " [4.5 1.5]\n",
      " [4.9 1.5]\n",
      " [4.  1.3]\n",
      " [4.6 1.5]\n",
      " [4.5 1.3]\n",
      " [4.7 1.6]\n",
      " [3.3 1. ]\n",
      " [4.6 1.3]\n",
      " [3.9 1.4]\n",
      " [3.5 1. ]\n",
      " [4.2 1.5]\n",
      " [4.  1. ]\n",
      " [4.7 1.4]\n",
      " [3.6 1.3]\n",
      " [4.4 1.4]\n",
      " [4.5 1.5]\n",
      " [4.1 1. ]\n",
      " [4.5 1.5]\n",
      " [3.9 1.1]\n",
      " [4.8 1.8]\n",
      " [4.  1.3]\n",
      " [4.9 1.5]\n",
      " [4.7 1.2]\n",
      " [4.3 1.3]\n",
      " [4.4 1.4]\n",
      " [4.8 1.4]\n",
      " [5.  1.7]\n",
      " [4.5 1.5]\n",
      " [3.5 1. ]\n",
      " [3.8 1.1]\n",
      " [3.7 1. ]\n",
      " [3.9 1.2]\n",
      " [5.1 1.6]\n",
      " [4.5 1.5]\n",
      " [4.5 1.6]\n",
      " [4.7 1.5]\n",
      " [4.4 1.3]\n",
      " [4.1 1.3]\n",
      " [4.  1.3]\n",
      " [4.4 1.2]\n",
      " [4.6 1.4]\n",
      " [4.  1.2]\n",
      " [3.3 1. ]\n",
      " [4.2 1.3]\n",
      " [4.2 1.2]\n",
      " [4.2 1.3]\n",
      " [4.3 1.3]\n",
      " [3.  1.1]\n",
      " [4.1 1.3]\n",
      " [6.  2.5]\n",
      " [5.1 1.9]\n",
      " [5.9 2.1]\n",
      " [5.6 1.8]\n",
      " [5.8 2.2]\n",
      " [6.6 2.1]\n",
      " [4.5 1.7]\n",
      " [6.3 1.8]\n",
      " [5.8 1.8]\n",
      " [6.1 2.5]\n",
      " [5.1 2. ]\n",
      " [5.3 1.9]\n",
      " [5.5 2.1]\n",
      " [5.  2. ]\n",
      " [5.1 2.4]\n",
      " [5.3 2.3]\n",
      " [5.5 1.8]\n",
      " [6.7 2.2]\n",
      " [6.9 2.3]\n",
      " [5.  1.5]\n",
      " [5.7 2.3]\n",
      " [4.9 2. ]\n",
      " [6.7 2. ]\n",
      " [4.9 1.8]\n",
      " [5.7 2.1]\n",
      " [6.  1.8]\n",
      " [4.8 1.8]\n",
      " [4.9 1.8]\n",
      " [5.6 2.1]\n",
      " [5.8 1.6]\n",
      " [6.1 1.9]\n",
      " [6.4 2. ]\n",
      " [5.6 2.2]\n",
      " [5.1 1.5]\n",
      " [5.6 1.4]\n",
      " [6.1 2.3]\n",
      " [5.6 2.4]\n",
      " [5.5 1.8]\n",
      " [4.8 1.8]\n",
      " [5.4 2.1]\n",
      " [5.6 2.4]\n",
      " [5.1 2.3]\n",
      " [5.1 1.9]\n",
      " [5.9 2.3]\n",
      " [5.7 2.5]\n",
      " [5.2 2.3]\n",
      " [5.  1.9]\n",
      " [5.2 2. ]\n",
      " [5.4 2.3]\n",
      " [5.1 1.8]]\n",
      "\n",
      "Coefficients Lasso:\n",
      " [ 0.         -0.          0.40811896  0.        ]\n"
     ]
    }
   ],
   "source": [
    "# filepath: c:\\Users\\michel.bertrand.mama\\Documents\\AYNID\\advanced_ml_best_practices.ipynb\n",
    "from sklearn.feature_selection import SelectKBest, chi2\n",
    "from sklearn.linear_model import Lasso\n",
    "from sklearn.datasets import load_iris\n",
    "import numpy as np\n",
    "\n",
    "# Charger les données Iris\n",
    "iris = load_iris()\n",
    "X, y = iris.data, iris.target\n",
    "\n",
    "# Méthode filter (SelectKBest avec chi2)\n",
    "select_k_best = SelectKBest(score_func=chi2, k=2)\n",
    "X_filter = select_k_best.fit_transform(X, y)\n",
    "print(\"Features sélectionnées par filter:\\n\", X_filter)\n",
    "\n",
    "# Méthode embedded (Lasso)\n",
    "lasso = Lasso(alpha=0.1)\n",
    "lasso.fit(X, y)\n",
    "print(\"\\nCoefficients Lasso:\\n\", lasso.coef_)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4c12cb3d",
   "metadata": {},
   "source": [
    "## 7.3 Mise en Production\n",
    "\n",
    "### Pipeline de ML\n",
    "\n",
    "Un pipeline de ML est un ensemble d'étapes de traitement des données et d'entraînement du modèle qui sont exécutées de manière séquentielle. Il permet d'automatiser le processus de Machine Learning et de garantir la reproductibilité des résultats.\n",
    "\n",
    "Les pipelines de ML comprennent généralement les étapes suivantes :\n",
    "\n",
    "*   **Collecte des données :** Rassembler les données nécessaires pour entraîner le modèle.\n",
    "*   **Préparation des données :** Nettoyer, transformer et préparer les données pour l'entraînement.\n",
    "*   **Sélection des features :** Sélectionner un sous-ensemble de features pertinentes.\n",
    "*   **Entraînement du modèle :** Utiliser les données d'entraînement pour apprendre les paramètres du modèle.\n",
    "*   **Évaluation du modèle :** Mesurer la performance du modèle sur des données de test.\n",
    "*   **Déploiement du modèle :** Mettre le modèle en production pour faire des prédictions sur de nouvelles données.\n",
    "\n",
    "Voici un exemple en Python utilisant `scikit-learn` :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ae03323e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# filepath: c:\\Users\\michel.bertrand.mama\\Documents\\AYNID\\advanced_ml_best_practices.ipynb\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.datasets import load_iris\n",
    "\n",
    "# Charger les données Iris\n",
    "iris = load_iris()\n",
    "X, y = iris.data, iris.target\n",
    "\n",
    "# Diviser les données en ensembles d'entraînement et de test\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)\n",
    "\n",
    "# Créer un pipeline\n",
    "pipeline = Pipeline([\n",
    "    ('scaler', StandardScaler()),\n",
    "    ('classifier', LogisticRegression())\n",
    "])\n",
    "\n",
    "# Entraîner le pipeline\n",
    "pipeline.fit(X_train, y_train)\n",
    "\n",
    "# Évaluer le pipeline\n",
    "accuracy = pipeline.score(X_test, y_test)\n",
    "print(\"Précision du pipeline:\", accuracy)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ef20bb7f",
   "metadata": {},
   "source": [
    "### Monitoring des modèles\n",
    "\n",
    "Le monitoring des modèles est le processus de suivi de la performance des modèles de Machine Learning en production. Il permet de détecter les problèmes de performance et de s'assurer que les modèles continuent de fournir des prédictions précises.\n",
    "\n",
    "Le monitoring des modèles comprend généralement les étapes suivantes :\n",
    "\n",
    "*   **Collecte des données :** Rassembler les données de production utilisées pour faire des prédictions.\n",
    "*   **Calcul des métriques de performance :** Mesurer la performance du modèle sur les données de production.\n",
    "*   **Détection des anomalies :** Identifier les problèmes de performance (par exemple, une baisse de la précision).\n",
    "*   **Investigation des causes :** Déterminer les causes des problèmes de performance (par exemple, une dérive des données).\n",
    "*   **Correction des problèmes :** Prendre des mesures pour corriger les problèmes de performance (par exemple, re-entraîner le modèle)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9030e72f",
   "metadata": {},
   "source": [
    "### Re-entraînement et dérive des données\n",
    "\n",
    "La dérive des données (data drift) est un phénomène qui se produit lorsque la distribution des données de production change au fil du temps. Cela peut entraîner une baisse de la performance des modèles de Machine Learning.\n",
    "\n",
    "Le re-entraînement des modèles est le processus de mise à jour des paramètres du modèle en utilisant de nouvelles données. Il permet de maintenir la performance du modèle face à la dérive des données.\n",
    "\n",
    "La fréquence de re-entraînement dépend de la vitesse à laquelle les données changent et de l'impact de la dérive des données sur la performance du modèle."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
